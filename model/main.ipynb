{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import keras\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torchvision.models._api import WeightsEnum\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "from Constants import *\n",
    "from dataset import *\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision import models\n",
    "#dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(\"../data/Training/glioma/Tr-glTr_0004.jpg\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(TRAIN_PATH,\n",
    "                                                           shuffle = True,\n",
    "                                                           image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                           batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(dataset)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "print(class_names)\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 4))\n",
    "for image_batch, label_batch in dataset.take(1):\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[label_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocessing(IMAGE_SIZE):\n",
    "    train_augmenting = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(p = 0.5),\n",
    "        transforms.RandomVerticalFlip(p = 0.5),\n",
    "        transforms.GaussianBlur(kernel_size = (5, 9),sigma = (0.1, 5)),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor = 2, p = 0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean = [0.485, 0.465, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return train_augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(TRAIN_PATH,\n",
    "                               transform = (train_preprocessing(IMAGE_SIZE)))\n",
    "dataset_size = [int(len(dataset) * 0.75), len(dataset) - int(len(dataset) * 0.75)]\n",
    "train_set, validation_set = random_split(dataset, dataset_size)\n",
    "\n",
    "def file_loader(train_set, validation_set):\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle = True,\n",
    "        num_workers = NUM_WORKERS\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle = False,\n",
    "        num_workers = NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def save_model(epochs, model, optimizer, criterion):\n",
    "    torch.save({\n",
    "        'epoch' : epochs,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'loss' : criterion,\n",
    "    }, f\"../outputs/model.pth\")\n",
    "    \n",
    "    \n",
    "def save_plots(train_accuracy, validation_accuracy, train_loss, validation_loss):\n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.plot(train_accuracy, color = 'black', label = 'training accuracy')\n",
    "    plt.plot(validation_accuracy, color = 'blue', label = 'validation accuracy')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../outputs/accuracy.png\")\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.plot(train_loss, color = 'black', label = 'training loss')\n",
    "    plt.plot(validation_loss, color = 'blue', label = 'validation loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"../outputs/loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained = True, fine_tune = True, num_classes = 4):\n",
    "    \"\"\"\n",
    "    Builds a ResNet model for image classification.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): Whether to load pre-trained weights.\n",
    "        fine_tune (bool): Whether to fine-tune all layers.\n",
    "        num_classes (int): Number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The built model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained ResNet model\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "    # Freeze all layers if fine-tuning is not enabled\n",
    "    if not fine_tune:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Change the final classification head to match the number of classes\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print(\"Training...\")\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for i, data in tqdm(enumerate(trainloader), total = len(trainloader)):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Calculating loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        # Calculating accuracy\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (prediction == labels).sum().item()\n",
    "        \n",
    "        # Backward prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_accuracy = 100 * (train_running_correct / len(trainloader.dataset))\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    print('validation...')\n",
    "    validation_running_loss = 0.0\n",
    "    validation_running_correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total = len(testloader)):\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward prop\n",
    "            outputs = model(image)\n",
    "            \n",
    "            # Calculating loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_running_loss += loss.item()\n",
    "            \n",
    "            # Calculating accuracy\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            validation_running_correct += (prediction == labels).sum().item()\n",
    "            \n",
    "    epoch_loss = validation_running_loss / counter\n",
    "    epoch_accuracy = 100 * (validation_running_correct / len(testloader.dataset))\n",
    "    \n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'learning_rate' : 0.0001, 'epochs' : 10}\n",
    "dataset_classes = dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation data loaders\n",
    "train_loader, validation_loader = file_loader(train_set, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "learning_rate = args['learning_rate']\n",
    "epochs = args['epochs']\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on: {device}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Epochs: {epochs}\\n\")\n",
    "    \n",
    "model = build_model(\n",
    "        pretrained = True,\n",
    "        fine_tune = True,\n",
    "        num_classes = len(dataset_classes)\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Total parameters and trainable parameters\n",
    "total_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_parameters:,} parameters.\")\n",
    "trainable_parameters = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{trainable_parameters:,} training parameters.\")\n",
    "    \n",
    "    # Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    # Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Tracking loss and accuracy\n",
    "train_loss, validation_loss = [], []\n",
    "train_accuracy, validation_accuracy = [], []\n",
    "    \n",
    "    # Train\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "    train_loss_per_epoch, train_accuracy_per_epoch = train(model,\n",
    "                                                               train_loader,\n",
    "                                                               optimizer,\n",
    "                                                               criterion)\n",
    "    val_loss_per_epoch, val_accuracy_per_epoch = validate(model,\n",
    "                                                              validation_loader,\n",
    "                                                              criterion)\n",
    "    train_loss.append(train_loss_per_epoch)\n",
    "    validation_loss.append(val_loss_per_epoch)\n",
    "    training_accuracy.append(train_accuracy_per_epoch)\n",
    "    validation_accuracy.append(val_accuracy_per_epoch)\n",
    "    print(f\"Training loss: {train_loss_per_epoch:.3f}, Training accuracy: {train_accuracy_per_epoch:.3f}\")\n",
    "    print(f\"Validation loss: {val_loss_per_epoch:.3f}, Validation accuracy: {val_accuracy_per_epoch:.3f}\")\n",
    "    #print(\"-.-\" * 10)\n",
    "    print(\"~ \" * 55)\n",
    "    time.sleep(3)\n",
    "        \n",
    "    # Save model\n",
    "save_model(epochs, model, optimizer, criterion)\n",
    "    # Save loss and accuracy plots\n",
    "save_plots(train_accuracy, validation_accuracy, train_loss, validation_loss)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n",
    "\n",
    "# Load saved model\n",
    "model = build_model(pretrained = False, fine_tune = False, num_classes = 4)\n",
    "checkpoint = torch.load(\"../outputs/model.pth\", map_location = DEVICE)\n",
    "#print(\"Loading saved model\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Get test files\n",
    "test_files = glob.glob(f\"{TEST_PATH}/*\")\n",
    "\n",
    "# Iterate over images\n",
    "for test_file in test_files:\n",
    "    # Get true class name and make copy\n",
    "    actual_class = test_file.split(os.path.sep)[-1].split('.')[0]\n",
    "    image = cv2.imread(test_file)\n",
    "    test_image = image.copy()\n",
    "    \n",
    "    # Preprocess images\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean = [0.485, 0.465, 0.406],\n",
    "            std = [0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    image = image.to(DEVICE)\n",
    "    \n",
    "    # Test on image\n",
    "    outputs = model(image)\n",
    "    outputs = outputs.detach().numpy()\n",
    "    predicted_class = class_names[np.argmax(outputs[0])]\n",
    "    print(f\"Actual class: {actual_class}, Predicted: {predicted_class.lower()}\")\n",
    "    \n",
    "    # Inscribe the text onto the images\n",
    "    cv2.putText(\n",
    "        test_image,\n",
    "        f\"Actual: {actual_class}\",\n",
    "        (10, 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (100, 100, 225),\n",
    "        #(65, 65, 155),\n",
    "        1,\n",
    "        lineType = cv2.LINE_AA\n",
    "    )\n",
    "    cv2.putText(\n",
    "        test_image,\n",
    "        f\"Predicted: {predicted_class.lower()}\",\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        #(100, 100, 225),\n",
    "        (65, 65, 155),\n",
    "        1,\n",
    "        lineType = cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    cv2.imshow(\"Result\", test_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite(f\"../outputs/{actual_class}.png\", test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
